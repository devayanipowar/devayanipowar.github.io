{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import udf,col\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc= SparkContext()\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('C:\\\\Users\\\\dpawa\\\\OneDrive\\\\Documents\\\\657\\\\asssign 2\\\\train.csv')\n",
    "#train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6372.8 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    distance =  c * r\n",
    "    return abs(round(distance, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_get_distance = F.udf(haversine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (train.withColumn('DISTANCE', udf_get_distance(\n",
    "train.pickup_longitude, train.pickup_latitude,\n",
    "train.dropoff_longitude, train.dropoff_latitude)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['pickup_longitude', 'pickup_latitude','dropoff_longitude','dropoff_latitude']\n",
    "train = train.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|       id|         vendor_id|   passenger_count|store_and_fwd_flag|    trip_duration|          DISTANCE|\n",
      "+-------+---------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|  1458644|           1458644|           1458644|           1458644|          1458644|           1458644|\n",
      "|   mean|     null|1.5349502688798637|1.6645295219395548|              null|959.4922729603659|2.1365657007467114|\n",
      "| stddev|     null|0.4987771539074011|1.3142421678231184|              null|5237.431724497624| 2.667889495100226|\n",
      "|    min|id0000001|                 1|                 0|                 N|                1|               0.0|\n",
      "|    max|id4000000|                 2|                 9|                 Y|          3526282|              9.99|\n",
      "+-------+---------+------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id2875421', vendor_id=2, pickup_datetime=datetime.datetime(2016, 3, 14, 17, 24, 55), dropoff_datetime=datetime.datetime(2016, 3, 14, 17, 32, 30), passenger_count=1, store_and_fwd_flag=0, trip_duration=455, DISTANCE='1.5')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.withColumn('store_and_fwd_flag', F.when(train.store_and_fwd_flag == 'N', 0).otherwise(1))\n",
    "train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id2875421', vendor_id=2, pickup_datetime=datetime.datetime(2016, 3, 14, 17, 24, 55), dropoff_datetime=datetime.datetime(2016, 3, 14, 17, 32, 30), passenger_count=1, store_and_fwd_flag=0, trip_duration=455, DISTANCE='1.5', Date='2016-03-14', Time='17:24:55', Year='2016', Month='03', Day='14', weekDay='1', hour='17', minutes='24', seconds='55')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "split_col = pyspark.sql.functions.split(train['pickup_datetime'], ' ')\n",
    "train = train.withColumn('Date', split_col.getItem(0))\n",
    "train = train.withColumn('Time', split_col.getItem(1))\n",
    "split_date=pyspark.sql.functions.split(train['Date'], '-')     \n",
    "train= train.withColumn('Year', split_date.getItem(0))\n",
    "train= train.withColumn('Month', split_date.getItem(1))\n",
    "train= train.withColumn('Day', split_date.getItem(2))\n",
    "funcWeekDay =  udf(lambda x: datetime.strptime(x, '%Y-%m-%d').strftime('%w'))\n",
    "train = train.withColumn('weekDay', funcWeekDay(col('Date')))\n",
    "split_date=pyspark.sql.functions.split(train['Time'], ':')     \n",
    "train= train.withColumn('hour', split_date.getItem(0))\n",
    "train= train.withColumn('minutes', split_date.getItem(1))\n",
    "train= train.withColumn('seconds', split_date.getItem(2))\n",
    "train.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id2875421', vendor_id=2, pickup_datetime=datetime.datetime(2016, 3, 14, 17, 24, 55), dropoff_datetime=datetime.datetime(2016, 3, 14, 17, 32, 30), passenger_count=1, store_and_fwd_flag=0, trip_duration=455, DISTANCE=1, Date='2016-03-14', Time='17:24:55', Year=2016, Month=3, Day=14, weekDay=1, hour=17, minutes=24, seconds=55)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.withColumn(\"Year\", train[\"Year\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"weekDay\", train[\"weekDay\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"Month\", train[\"Month\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"Day\", train[\"Day\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"hour\", train[\"hour\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"minutes\", train[\"minutes\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"seconds\", train[\"seconds\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"DISTANCE\", train[\"DISTANCE\"].cast(IntegerType()))\n",
    "\n",
    "train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['pickup_datetime','dropoff_datetime', 'Date','Time']\n",
    "train = train.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+\n",
      "|       id|vendor_id|passenger_count|store_and_fwd_flag|trip_duration|DISTANCE|Year|Month|Day|weekDay|hour|minutes|seconds|\n",
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+\n",
      "|id2875421|        2|              1|                 0|          455|       0|2016|    3| 14|      1|  17|     24|     55|\n",
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+----------------+\n",
      "|       id|vendor_id|passenger_count|store_and_fwd_flag|trip_duration|DISTANCE|Year|Month|Day|weekDay|hour|minutes|seconds|    log_duration|\n",
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+----------------+\n",
      "|id2875421|        2|              1|                 0|          455|       1|2016|    3| 14|      1|  17|     24|     55|6.12029741895095|\n",
      "+---------+---------+---------------+------------------+-------------+--------+----+-----+---+-------+----+-------+-------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import log\n",
    "train = train.withColumn(\"log_duration\", log(train[\"trip_duration\"]) )\n",
    "train.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- vendor_id: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: integer (nullable = false)\n",
      " |-- trip_duration: integer (nullable = true)\n",
      " |-- DISTANCE: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- weekDay: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- log_duration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.cache()\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "      <td>1458644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5349502688798637</td>\n",
       "      <td>1.6645295219395548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>959.4922729603659</td>\n",
       "      <td>3.4408639325291177</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.516817674497684</td>\n",
       "      <td>15.504018115455176</td>\n",
       "      <td>3.1128177951576945</td>\n",
       "      <td>13.60648451575573</td>\n",
       "      <td>29.59015770811795</td>\n",
       "      <td>29.473590540255195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4987771539074011</td>\n",
       "      <td>1.3142421678231184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5237.431724497624</td>\n",
       "      <td>4.296542880941734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6810375087348843</td>\n",
       "      <td>8.703135115281617</td>\n",
       "      <td>1.9928049699468888</td>\n",
       "      <td>6.399692034352387</td>\n",
       "      <td>17.324714120895614</td>\n",
       "      <td>17.319851679258015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>id0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>id4000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3526282</td>\n",
       "      <td>97.59</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         id           vendor_id     passenger_count  \\\n",
       "0   count    1458644             1458644             1458644   \n",
       "1    mean       None  1.5349502688798637  1.6645295219395548   \n",
       "2  stddev       None  0.4987771539074011  1.3142421678231184   \n",
       "3     min  id0000001                   1                   0   \n",
       "4     max  id4000000                   2                   9   \n",
       "\n",
       "  store_and_fwd_flag      trip_duration            DISTANCE     Year  \\\n",
       "0            1458644            1458644             1458644  1458644   \n",
       "1                1.0  959.4922729603659  3.4408639325291177   2016.0   \n",
       "2                0.0  5237.431724497624   4.296542880941734      0.0   \n",
       "3                  1                  1                 0.0     2016   \n",
       "4                  1            3526282               97.59     2016   \n",
       "\n",
       "                Month                 Day             weekDay  \\\n",
       "0             1458644             1458644             1458644   \n",
       "1   3.516817674497684  15.504018115455176  3.1128177951576945   \n",
       "2  1.6810375087348843   8.703135115281617  1.9928049699468888   \n",
       "3                   1                   1                   0   \n",
       "4                   6                  31                   6   \n",
       "\n",
       "                hour             minutes             seconds  \n",
       "0            1458644             1458644             1458644  \n",
       "1  13.60648451575573   29.59015770811795  29.473590540255195  \n",
       "2  6.399692034352387  17.324714120895614  17.319851679258015  \n",
       "3                  0                   0                   0  \n",
       "4                 23                  59                  59  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|      log_duration|\n",
      "+--------------------+------------------+\n",
      "|[2.0,1.0,0.0,1.0,...|  6.12029741895095|\n",
      "|[1.0,1.0,0.0,1.0,...|6.4967749901858625|\n",
      "|[2.0,1.0,0.0,6.0,...|  7.66105638236183|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols = ['vendor_id', 'passenger_count', 'store_and_fwd_flag','DISTANCE', 'Year', 'Month','Day','weekDay','hour','minutes','seconds'], outputCol = 'features')\n",
    "vtrain = vectorAssembler.transform(train)\n",
    "vtrain = vtrain.select(['features', 'log_duration'])\n",
    "vtrain.show(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vtrain.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'log_duration',maxDepth = 2)\n",
    "#dt_model = dt.fit(train_df)\n",
    "#dt_predictions = dt_model.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRt\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"log_duration\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "#rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "#print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidatorModel_26a4ed946038\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [2, 3,5])\n",
    "             .addGrid(dt.maxBins, [4, 8,32])\n",
    "             .build())\n",
    "\n",
    "dtcv = CrossValidator(estimator = dt,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = dt_evaluator,\n",
    "                      numFolds = 10)\n",
    "\n",
    "# Run cross validations\n",
    "dtcvModel = dtcv.fit(train_df)\n",
    "print(dtcvModel)\n",
    "dtpredictions = dtcvModel.transform(test_df)\n",
    "\n",
    "# Use test set here so we can measure the accuracy of our model on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean Absolute Error (MAE) on test data = 0.340612\n"
     ]
    }
   ],
   "source": [
    "mae = dt_evaluator.evaluate(dtpredictions)\n",
    "print(\" Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.513194\n"
     ]
    }
   ],
   "source": [
    "rmse = dt_evaluator.evaluate(dtpredictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpredictions_ert = dtcvModel.transform(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(11, {0: 1.0, 1: 2.0, 4: 2016.0, 5: 2.0, 6: 14.0, 9: 17.0}), log_duration=5.3230099791384085, prediction=5.341284741186751),\n",
       " Row(features=SparseVector(11, {0: 2.0, 1: 1.0, 4: 2016.0, 5: 5.0, 6: 15.0, 9: 15.0}), log_duration=5.814130531825066, prediction=5.341284741186751)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtpredictions_ert.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(11, {0: 2.0, 1: 1.0, 4: 2016.0, 5: 2.0, 6: 28.0, 9: 23.0}), log_duration=5.493061443340548, prediction=5.711890426639655),\n",
       " Row(features=SparseVector(11, {0: 2.0, 1: 2.0, 4: 2016.0, 5: 2.0, 6: 7.0, 9: 55.0}), log_duration=5.54907608489522, prediction=5.711890426639655)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtpredictions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        prediction|\n",
      "+------------------+\n",
      "| 6.284032803395688|\n",
      "|6.0485785145505995|\n",
      "| 5.946427673262689|\n",
      "| 6.141958153601273|\n",
      "| 6.551517246541201|\n",
      "|7.1425228143753525|\n",
      "| 7.545394329958232|\n",
      "| 7.298411167160363|\n",
      "|5.7496543843581795|\n",
      "| 7.924025245291648|\n",
      "|6.7242448681574745|\n",
      "| 5.341284741186751|\n",
      "| 6.786321805577687|\n",
      "| 7.279632571860633|\n",
      "|6.4916823051830965|\n",
      "|5.9916296670176505|\n",
      "| 6.682920331289729|\n",
      "| 5.432234644903332|\n",
      "| 5.122152969922232|\n",
      "| 6.092726346118731|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_table = dtpredictions.groupBy('prediction').count()\n",
    "pred_table = pred_table.drop('count')\n",
    "pred_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|        prediction| count|\n",
      "+------------------+------+\n",
      "| 6.284032803395688| 27037|\n",
      "|6.0485785145505995| 28532|\n",
      "| 5.946427673262689| 26135|\n",
      "| 6.141958153601273| 35344|\n",
      "| 6.551517246541201| 22270|\n",
      "|7.1425228143753525| 38084|\n",
      "| 7.545394329958232| 48256|\n",
      "| 7.298411167160363| 49836|\n",
      "|5.7496543843581795| 13042|\n",
      "| 7.924025245291648| 26899|\n",
      "|6.7242448681574745| 14875|\n",
      "| 5.341284741186751| 13475|\n",
      "| 6.786321805577687| 47976|\n",
      "| 7.279632571860633| 12740|\n",
      "|6.4916823051830965| 61864|\n",
      "|5.9916296670176505| 36084|\n",
      "| 6.682920331289729|116061|\n",
      "| 5.432234644903332| 14672|\n",
      "| 5.122152969922232|  9770|\n",
      "| 6.092726346118731|  8156|\n",
      "+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_table1 = dtpredictions_ert.groupBy('prediction').count()\n",
    "pred_table1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predlist = pred_table.select(\"prediction\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.284032803395688"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predlist = pred_table.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "predlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "lr = LinearRegression(featuresCol ='features', labelCol = 'log_duration',maxIter=10)\n",
    "#lr_model = lr.fit(newdf)\n",
    "evaluator = RegressionEvaluator(labelCol=\"log_duration\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01,0.3,0.5,1]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.1,0.2, 0.5, 0.8,1.0])\\\n",
    "    .build()\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae on test data = 0.401267\n",
      "mae on test data = 0.500687\n",
      "mae on test data = 0.478158\n",
      "mae on test data = 0.503749\n",
      "mae on test data = 0.403103\n",
      "mae on test data = 0.346481\n",
      "mae on test data = 0.361704\n",
      "mae on test data = 0.370933\n",
      "mae on test data = 0.438178\n",
      "mae on test data = 0.358747\n",
      "mae on test data = 0.353605\n",
      "mae on test data = 0.832952\n",
      "mae on test data = 0.360192\n",
      "mae on test data = 0.321652\n",
      "mae on test data = 0.388788\n",
      "mae on test data = 0.444754\n",
      "mae on test data = 0.436411\n",
      "mae on test data = 0.837187\n",
      "mae on test data = 0.908399\n",
      "mae on test data = 0.464472\n",
      "mae on test data = 0.397229\n",
      "mae on test data = 0.341766\n",
      "mae on test data = 0.781383\n",
      "mae on test data = 0.387552\n",
      "mae on test data = 0.33334\n",
      "mae on test data = 0.774761\n",
      "mae on test data = 0.726717\n",
      "mae on test data = 0.498695\n",
      "mae on test data = 0.429825\n",
      "mae on test data = 0.399224\n",
      "mae on test data = 1.66699\n",
      "mae on test data = 0.790693\n"
     ]
    }
   ],
   "source": [
    "for i in predlist:\n",
    "    newdf = dtpredictions.filter(dtpredictions.prediction == i)\n",
    "    newdft = dtpredictions_ert.filter(dtpredictions_ert.prediction == i)\n",
    "    newdf = newdf.drop('prediction')\n",
    "    newdft = newdft.drop('prediction')\n",
    "    model = tvs.fit(newdft)\n",
    "    lr_predictions = model.transform(newdf)\n",
    "    rmse = dt_evaluator.evaluate(lr_predictions)\n",
    "    print(\"mae on test data = %g\" % rmse)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
