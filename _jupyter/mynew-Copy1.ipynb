{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(lines):\n",
    "    lines = lines.split()\n",
    "    return lines\n",
    "\n",
    "lines = sc.textFile(\"C:\\\\Users\\\\dpawa\\\\OneDrive\\\\Documents\\\\stateoftheunion1790-2019.txt\").map(fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('george', 'favorable')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = Row('sentence') # Or some other column name\n",
    "df = lines.map(row).toDF()\n",
    "remover = StopWordsRemover(inputCol=\"sentence\", outputCol=\"filtered\")\n",
    "filter_list = remover.transform(df)\n",
    "filter_list = filter_list.drop('sentence')\n",
    "rdd1 = filter_list.rdd.flatMap(lambda x: x)\n",
    "rdd_combo = rdd1.flatMap(lambda x: list(set(combinations(x,2))))\n",
    "rdd_combo.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_f = rdd_combo.map(lambda x : (x , 1)).reduceByKey(lambda a, b: a+b).filter(lambda x : x[1] > 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onedf = rdd_f.map(lambda x : (x[0][0],x[1]))\n",
    "table1 = spark.createDataFrame(onedf,['onedf','count_f'])\n",
    "twodf = rdd_f.map(lambda x : (x[0][1],x[1]))\n",
    "table2 = spark.createDataFrame(twodf,['twodf','count_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = rdd_f.map(lambda x : (x[0][0],x[0][1],x[1]))\n",
    "table = spark.createDataFrame(first,['first','second','count1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         word|count|\n",
      "+-------------+-----+\n",
      "|      embrace|   47|\n",
      "|         hope|  842|\n",
      "|        still| 1055|\n",
      "|  transaction|   44|\n",
      "|    standards|  166|\n",
      "|apprehensions|   37|\n",
      "|    connected|  177|\n",
      "|      implore|    4|\n",
      "|          art|   51|\n",
      "| accumulation|   50|\n",
      "|     inimical|    7|\n",
      "|       spared|   39|\n",
      "|  transmitted|  126|\n",
      "|         clog|    2|\n",
      "|precautionary|   14|\n",
      "|    involving|   85|\n",
      "|    destitute|   27|\n",
      "|  unequivocal|   11|\n",
      "|  unavoidably|   12|\n",
      "|gratification|   41|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "table3 = filter_list.withColumn('word', f.explode(f.col('filtered')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\n",
    "    \n",
    "table3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------+------------+-----+--------------------+\n",
      "|        first|      second|count1|        word|count|              P(A/B)|\n",
      "+-------------+------------+------+------------+-----+--------------------+\n",
      "|      prevent|accumulation|     8|accumulation|   50|                0.16|\n",
      "|        great|accumulation|     6|accumulation|   50|                0.12|\n",
      "|          may|accumulation|     8|accumulation|   50|                0.16|\n",
      "|   government|accumulation|     6|accumulation|   50|                0.12|\n",
      "|        given|  commanders|     6|  commanders|   58| 0.10344827586206896|\n",
      "|         last|  commanders|     7|  commanders|   58|  0.1206896551724138|\n",
      "|     military|  commanders|    16|  commanders|   58| 0.27586206896551724|\n",
      "|        naval|  commanders|    15|  commanders|   58| 0.25862068965517243|\n",
      "|         many|   connected|     9|   connected|  177| 0.05084745762711865|\n",
      "|    secretary|   connected|    10|   connected|  177| 0.05649717514124294|\n",
      "|      service|   connected|    15|   connected|  177|  0.0847457627118644|\n",
      "|      subject|   connected|     9|   connected|  177| 0.05084745762711865|\n",
      "|circumstances|   connected|     7|   connected|  177| 0.03954802259887006|\n",
      "|   government|   connected|    11|   connected|  177|0.062146892655367235|\n",
      "|       report|   connected|    10|   connected|  177| 0.05649717514124294|\n",
      "|     question|   connected|     6|   connected|  177| 0.03389830508474576|\n",
      "|          men|   connected|     7|   connected|  177| 0.03954802259887006|\n",
      "|    important|   connected|     8|   connected|  177| 0.04519774011299435|\n",
      "|          war|   connected|    11|   connected|  177|0.062146892655367235|\n",
      "|         last|   connected|     7|   connected|  177| 0.03954802259887006|\n",
      "+-------------+------------+------+------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "ta = table.alias('ta')\n",
    "tb = table3.alias('tb')\n",
    "\n",
    "\n",
    "inner_join = table.join(tb, ta.second == tb.word)\\\n",
    "    .withColumn(\"P(A/B)\", (F.col(\"count1\") / F.col(\"count\")))\n",
    "inner_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+----------+-----+-------------------+\n",
      "|     first|    second|count1|      word|count|             P(A/B)|\n",
      "+----------+----------+------+----------+-----+-------------------+\n",
      "|    united|    states|  4132|    states| 6508| 0.6349108789182545|\n",
      "|government|    states|   729|    states| 6508| 0.1120159803318992|\n",
      "|    fiscal|      year|   705|      year| 3946|0.17866193613786113|\n",
      "|    states|    states|   634|    states| 6508|0.09741856177012907|\n",
      "|      last|      year|   626|      year| 3946|0.15864166244298022|\n",
      "|    states|government|   570|government| 7032| 0.0810580204778157|\n",
      "|government|    united|   563|    united| 4847|0.11615432226119249|\n",
      "|government|government|   549|government| 7032| 0.0780716723549488|\n",
      "|  congress|    states|   503|    states| 6508|0.07728948985863553|\n",
      "|     great|   britain|   496|   britain|  530| 0.9358490566037736|\n",
      "|government|    people|   474|    people| 4017| 0.1179985063480209|\n",
      "|     state|     union|   461|     union| 1330|0.34661654135338343|\n",
      "|    united|government|   448|government| 7032|0.06370875995449374|\n",
      "|    states|    united|   447|    united| 4847|0.09222199298535176|\n",
      "|   federal|government|   445|government| 7032|0.06328213879408419|\n",
      "|  american|    people|   442|    people| 4017|0.11003236245954692|\n",
      "|      last|   session|   418|   session|  805| 0.5192546583850932|\n",
      "|      upon|government|   391|government| 7032|0.05560295790671217|\n",
      "|      last|  congress|   388|  congress| 5025| 0.0772139303482587|\n",
      "|    united|    united|   379|    united| 4847| 0.0781926965133072|\n",
      "+----------+----------+------+----------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "inner_join.sort(col(\"count1\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "sort_df = inner_join.filter(\"`P(A/B)` > 0.8\")\n",
    "sort_df.toPandas().to_csv(\"C:\\\\Users\\\\dpawa\\\\OneDrive\\\\Documents\\\\657\\\\assign_1_657_Pawar\\\\output\\\\probabilityandcoocc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
